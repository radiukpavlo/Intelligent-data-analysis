{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>Лекція 4. Лінійні моделі класифікації і регресії\n",
    "## <center>Частина 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"4-2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Зміст \n",
    "\n",
    "- [4.3. Приклад регуляризації логістичної регресії](#4.3)\n",
    "    + [4.3.1. Логістична регресія з поліноміальними ознаками](#4.3.1)\n",
    "    + [4.3.2. Налаштування параметра регуляризації](#4.3.2)\n",
    "- [4.4. Приклади застосування регуляризації](#4.4)\n",
    "    + [4.4.1. Аналіз відгуків IMDB до фільмів](#4.4.1)\n",
    "    + [4.4.2. Простий підрахунок слів](#4.4.2)\n",
    "    + [4.4.3. XOR-проблема](#4.4.3)\n",
    "- [4.5. Криві валідації й навчання](#4.5)\n",
    "    + [4.5.1. Як покращити модель?](#4.5.1)\n",
    "    + [4.5.2. Скільки потрібно даних?](#4.5.2)\n",
    "- [Висновки](#4.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"4.3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <span style=\"color:blue; font-size:1.2em;\">4.3. Приклад регуляризації логістичної регресії</span>\n",
    "\n",
    "[Повернутися до змісту](#4-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "У 1-ій частині лекції вже наводився приклад того, як поліноміальні ознаки дають змогу лінійним моделям будувати нелінійні розділяючі поверхні. Покажемо це на рисунках.\n",
    "\n",
    "Подивимося, як регуляризація впливає на якість класифікації за набором даних щодо тестування мікрочіпів з курсу Andrew Ng [Machine Learning](https://www.coursera.org/learn/machine-learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"4.3.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### <span style=\"color:blue; font-size:1.2em;\">4.3.1. Логістична регресія з поліноміальними ознаками</span>\n",
    "\n",
    "[Повернутися до змісту](#4-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Будемо використовувати логістичну регресію з поліноміальними ознаками і змінювати значення параметра регуляризації C. Спочатку подивимося, як регуляризація впливає на розділяючу границю класифікатора, інтуїтивно розпізнаємо перенавчання і недонавчання. Далі чисельно встановимо близький до оптимального параметр регуляризації за допомогою крос-валідації (`cross-validation`) і сіточного перебору (`GridSearch`).\n",
    "\n",
    "Для відображення графіків інсталюйте бібліотеку [drawdata](https://pypi.org/project/drawdata/):\n",
    "\n",
    "```python\n",
    "pip install drawdata\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "# відключимо всякі попередження Anaconda\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# підвищимо розмір графіків за замовчуванням\n",
    "# %config InlineBackend.figure_format = 'svg' \n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = 7, 5\n",
    "\n",
    "from drawdata import draw_scatter, draw_line, draw_histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Завантажуємо дані за допомогою методу `read_csv` бібліотеки` pandas`. У цьому наборі даних для 118 мікрочіпів (об'єкти) вказані результати двох тестів з контролю якості (дві числові ознаки) і вказано чи запустили мікрочіп у виробництво. Ознаки вже центровані, тобто від усіх значень віднято середні значення за стовпцями. Так, \"середньому\" мікрочіпу відповідають нульові значення результатів тестів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# завантаження данних\n",
    "data_microchip_tests = 'https://raw.githubusercontent.com/radiukpavlo/intelligent-data-analysis/main/01_lecture-notes/ida_lecture-04_linear_models/microchip_tests.txt'\n",
    "\n",
    "data = pd.read_csv(data_microchip_tests,\n",
    "                   header=None, names = ('test1','test2','released'))\n",
    "\n",
    "# інформація про набір даних\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Подивимося на перші й останні 5 рядків."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Збережемо навчальну вибірку й мітки цільового класу в окремих масивах `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X = data.iloc[:,:2].values\n",
    "y = data.iloc[:,2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Відобразимо дані. Червоний колір відповідає чіпам зі станом Defective, зелений – нормальним."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], c='green', label='Released')\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], c='red', label='Defective')\n",
    "plt.xlabel(\"Test 1\");plt.ylabel(\"Test 2\")\n",
    "plt.title('2 microchip tests')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Визначаємо функцію для відображення розділяючої кривої класифікатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def plot_boundary(clf, X, y, grid_step=.01, poly_featurizer=None):\n",
    "    x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
    "    y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, grid_step),\n",
    "                         np.arange(y_min, y_max, grid_step))\n",
    "\n",
    "    # кожній точці в сітці [x_min, m_max]x[y_min, y_max]\n",
    "    # ставимо у відповідність свій колір\n",
    "    Z = clf.predict(poly_featurizer.transform(np.c_[xx.ravel(), yy.ravel()]))\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contour(xx, yy, Z, cmap=plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Поліноміальними ознаками до степеня $d$ для двох змінних $x_1$ і $x_2$ ми називаємо такі:\n",
    "\n",
    "$$\\large \\{x_1^d, x_1^{d-1}x_2, \\ldots x_2^d\\} =  \\{x_1^ix_2^j\\}_{i+j=d, i,j \\in \\mathbb{N}}$$\n",
    "\n",
    "Наприклад, для $d=3$ це будуть такі ознаки:\n",
    "\n",
    "$$\\large 1, x_1, x_2,  x_1^2, x_1x_2, x_2^2, x_1^3, x_1^2x_2, x_1x_2^2, x_2^3$$\n",
    "\n",
    "Намалювавши трикутник Піфагора, ви зрозумієте, скільки таких ознак буде для $d=4,5...$ і взагалі для будь-якого $d$.\n",
    "Простіше кажучи, таких ознак експоненціально багато, і будувати, скажімо, для 100 ознак поліноміальні степеня 10 може виявитися затратно (а більш того, і не потрібно)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Створимо об'єкт `sklearn`, який додасть до матриці $X$ поліноміальні ознаки аж до степеня 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=7)\n",
    "X_poly = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_poly.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Навчимо логістичну регресію з параметром регуляризації $C = 10^{-2}$. Подамо розділяючу границю. Також перевіримо частку правильних відповідей класифікатора за навчальною вибіркою. Бачимо, що регуляризація виявилася занадто сильною, і модель \"недонавчилась\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "C = 1e-2\n",
    "logit = LogisticRegression(C=C, n_jobs=-1, random_state=17)\n",
    "logit.fit(X_poly, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boundary(logit, X, y, grid_step=.01, poly_featurizer=poly)\n",
    "\n",
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], c='green', label='Released')\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], c='red', label='Defective')\n",
    "plt.xlabel(\"Test 1\"); plt.ylabel(\"Test 2\")\n",
    "plt.title('2 microchip tests; logit with C=0.01')\n",
    "plt.legend();\n",
    "\n",
    "print(f\"Частка правильних відповідей класифікатора за навчальною вибіркою:\n",
    "      {round(logit.score(X_poly, y), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Збільшимо $C$ до 1. У такий спосіб ми *послаблюємо* регуляризацію. Тепер у рішенні значення ваг логістичної регресії можуть виявитися більшими (за модулем), ніж в попередньому випадку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "C = 1\n",
    "logit = LogisticRegression(C=C, n_jobs=-1, random_state=17)\n",
    "logit.fit(X_poly, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boundary(logit, X, y, grid_step=.005, poly_featurizer=poly)\n",
    "\n",
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], c='green', label='Released')\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], c='red', label='Defective')\n",
    "plt.xlabel(\"Test 1\"); plt.ylabel(\"Test 2\")\n",
    "plt.title('2 microchip tests; logit with C=1')\n",
    "plt.legend()\n",
    "\n",
    "print(f\"Частка правильних відповідей класифікатора за навчальною вибіркою: \n",
    "      {round(logit.score(X_poly, y), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ще збільшимо $C$ – до 10 тисяч. Тепер регуляризації явно недостатньо, і ми спостерігаємо перенавчання. Можнемо помітити, що в попередньому випадку (за $C$ = 1 і \"округлою\" границею) частка правильних відповідей моделі за навчальною вибіркою не набагато нижча, ніж в третьому випадку, зате за новою вибіркою можемо припустити, що друга модель спрацює значно краще."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "C = 1e4\n",
    "logit = LogisticRegression(C=C, n_jobs=-1, random_state=17)\n",
    "logit.fit(X_poly, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boundary(logit, X, y, grid_step=.005, poly_featurizer=poly)\n",
    "\n",
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], c='green', label='Released')\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], c='red', label='Defective')\n",
    "plt.xlabel(\"Test 1\"); plt.ylabel(\"Test 2\")\n",
    "plt.title('2 microchip tests; logit with C=10k')\n",
    "plt.legend()\n",
    "\n",
    "print(f\"Частка правильних відповідей класифікатора за навчальною вибіркою:\n",
    "      {round(logit.score(X_poly, y), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Щоб обговорити результати, перепишемо формулу для функціоналу, що оптимізується в логістичній регресії, в такому вигляді:\n",
    "\n",
    "$$\\large  J(X,y,w) = \\mathcal{L} + \\frac{1}{C}||w||^2,$$\n",
    "\n",
    "де\n",
    " - $\\mathcal{L}$ – логістична функція втрат, що просумована за всією вибіркою;\n",
    " - $C$ – обернений коефіцієнт регуляризації (тієї самої $C$ в `sklearn`-реалізації `LogisticRegression`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Проміжні висновки**:\n",
    " \n",
    " - чим більше значення параметру $C$, тим складніші залежності в даних може відновлювати модель (інтуїтивно $C$ відповідає \"складності\" моделі ([model capacity](https://en.wikipedia.org/wiki/Capacity_theory#Three_basic_components_of_the_capacity_model)));\n",
    " - якщо регуляризація занадто сильна (малі значення $C$), то розв'язком задачі мінімізації логістичної функції втрат може виявитися те, коли багато ваг обнулилися або стали занадто малим;  говорять також, що модель недостатньо \"штрафується\" за помилки (тобто у функціоналі $J$ \"переважує\" сума квадратів ваг, а помилка $\\mathcal{L}$ може бути відносно великою); в такому випадку модель виявиться *недонавченою* (1 випадок);\n",
    " - навпаки, якщо регуляризація занадто слабка (великі значення $C$), то розв'язком задачі оптимізації може стати вектор $w$ з великими за модулем компонентами; в такому випадку більший внесок в оптимізуючий функціонал $J$ має $\\mathcal{L}$ і, простіше кажучи, модель занадто \"боїться\" помилитися на об'єктах навчальної вибірки, тому отримаємо *перенавчання* (3 випадок);\n",
    " - то, яке значення $C$ вибрати, сама логістична регресія \"не зрозуміє\" (або ще кажуть \"не вивчить\"), тобто це не може бути визначено розв'язком оптимізаційної задачі, якою є логістична регресія (на відміну від ваг $w$ ); так само точно, дерево рішень не може \"саме зрозуміти\", яке обмеження на глибину вибрати (за один процес навчання); тому $C$ – це *гіперпараметр* моделі, який налаштовується під час крос-валідації, аналогічно до *max_depth* для дерева."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"4.3.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### <span style=\"color:blue; font-size:1.2em;\">4.3.2. Налаштування параметра регуляризації</span>\n",
    "\n",
    "[Повернутися до змісту](#4-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Тепер знайдемо оптимальне (в даному прикладі) значення параметра регуляризації $C$. Ми можемо це зробити допомогою `LogisticRegressionCV` – перебору параметрів по сітці з наступною крос-валідацією. Цей клас створений спеціально для логістичної регресії (для неї відомі ефективні алгоритми перебору параметрів), для довільної моделі ми б використовували `GridSearchCV`, `RandomizedSearchCV` або, наприклад, спеціальні алгоритми оптимізації гіперпараметров, що реалізовані в [hyperopt](http://hyperopt.github.io/hyperopt/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\n",
    "\n",
    "c_values = np.logspace(-2, 3, 500)\n",
    "\n",
    "logit_searcher = LogisticRegressionCV(Cs=c_values, cv=skf, verbose=1, n_jobs=-1)\n",
    "logit_searcher.fit(X_poly, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "logit_searcher.C_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Подивимося, як якість моделі (частка правильних відповідей за навчальною та валідаційною вибірками) змінюється у разі зміни гіперпараметра $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "plt.plot(c_values, np.mean(logit_searcher.scores_[1], axis=0))\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Mean CV-accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Виділимо ділянку з \"кращими\" значеннями C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "plt.plot(c_values, np.mean(logit_searcher.scores_[1], axis=0))\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Mean CV-accuracy')\n",
    "plt.xlim((0,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Такі криві називаються *валідаційними*, і в `sklearn` для їхньої побудови є спеціальні методи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"4.4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <span style=\"color:blue; font-size:1.2em;\">4.4. Приклади застосування регуляризації</span>\n",
    "\n",
    "[Повернутися до змісту](#4-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"4.4.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### <span style=\"color:blue; font-size:1.2em;\">4.4.1. Аналіз відгуків IMDB до фільмів</span>\n",
    "\n",
    "[Повернутися до змісту](#4-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Будемо розв'язувати задачу бінарної класифікації відгуків IMDb до фільмів (Набір даних [Large Movie Review Dataset v1.0](https://ai.stanford.edu/~amaas/data/sentiment/)). Є навчальна вибірка з розміченими відгуками, щодо 12500 відгуків відомо, що вони хороші, ще про 12500 – що вони погані. Тут вже не так просто відразу розпочати з МН, тому що готової матриці чинників $X$ немає – її треба підготувати. Будемо використовувати найпростіший підхід – мішок слів (\"Bag of words\"). За такого підходу ознаками відгуку будуть індикатори наявності в ньому кожного слова з усього корпусу, де корпус – це множина всіх відгуків. Ідея ілюструється рисунком:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![img](https://raw.githubusercontent.com/radiukpavlo/intelligent-data-analysis/main/03_img/4_2_10_bag_of_words.png)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Завантажимо дані [звідси](http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz) (це пряме покликання на завантаження, а [тут](http://ai.stanford.edu/~amaas/data/sentiment/) опис набору даних). У навчальній і тестовій вибірках по 12500 тисяч хороших і поганих відгуків до фільмів."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "from io import BytesIO\n",
    "import requests\n",
    "import tarfile\n",
    "\n",
    "url = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "def load_imdb_dataset(extract_path=\".\", overwrite=False):\n",
    "    #check if existed already\n",
    "    if os.path.isfile(os.path.join(extract_path, \"aclImdb\", \"README\")) and not overwrite:\n",
    "        print(f\"IMDB dataset is already in place.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Downloading the dataset from: {url}\")\n",
    "    response = requests.get(url)\n",
    "\n",
    "    tar = tarfile.open(mode= \"r:gz\", fileobj = BytesIO(response.content))\n",
    "\n",
    "    data = tar.extractall(extract_path)\n",
    "\n",
    "load_imdb_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "PATH_TO_IMDB = \"aclImdb\"\n",
    "\n",
    "try:\n",
    "    reviews_train = load_files(os.path.join(PATH_TO_IMDB, \"train\"), categories=['pos', 'neg'])\n",
    "    text_train, y_train = reviews_train.data, reviews_train.target\n",
    "    reviews_test = load_files(os.path.join(PATH_TO_IMDB, \"test\"), categories=['pos', 'neg'])\n",
    "    text_test, y_test = reviews_test.data, reviews_test.target\n",
    "except FileNotFoundError:\n",
    "    print(f\"The directory {PATH_TO_IMDB} does not exist. Please check the path and try again.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Number of documents in training data: {len(text_train)}\")\n",
    "print(np.bincount(y_train))\n",
    "print(f\"Number of documents in test data: {len(text_test)}\")\n",
    "print(np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Приклади відгуку та відповідної мітки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(text_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "y_train[1] # поганий відгук"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_train[2] # хороший відгук"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"4.4.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### <span style=\"color:blue; font-size:1.2em;\">4.4.2. Простий підрахунок слів</span>\n",
    "\n",
    "[Повернутися до змісту](#4-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Складемо словник усіх слів за допомогою CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "cv.fit(text_train)\n",
    "\n",
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Подивимося на приклади отриманих \"слів\" (краще їх називати токенами). Бачимо, що багато важливих етапів оброблення тексту ми тут пропустили."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(cv.get_feature_names_out()[:50])\n",
    "print(cv.get_feature_names_out()[50000:50050])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Закодуємо пропозиції з текстів навчальної вибірки індексами вхідних слів. Використовуємо розріджений формат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_train = cv.transform(text_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Подивимося, як перетворення подіяло на одну з пропозицій:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(text_train[19726])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_train[19726].nonzero()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_train[19726].nonzero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Перетворимо так само тестову вибірку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_test = cv.transform(text_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Навчимо логістичну регресію:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "logit = LogisticRegression(n_jobs=-1, random_state=7)\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Подивимося на частки правильних відповідей за навчальною і тестовою вибірками:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "round(logit.score(X_train, y_train), 3), round(logit.score(X_test, y_test), 3),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Коефіцієнти моделі можна гарно відобразити:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_coefficients(classifier, feature_names, n_top_features=25):\n",
    "    \n",
    "    # отримуємо коефіцієнти з великими абсолютними значеннями\n",
    "    coef = classifier.coef_.ravel()\n",
    "    positive_coefficients = np.argsort(coef)[-n_top_features:]\n",
    "    negative_coefficients = np.argsort(coef)[:n_top_features]\n",
    "    interesting_coefficients = np.hstack([negative_coefficients, positive_coefficients])\n",
    "    \n",
    "    # відобразимо коефіцієнти\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    colors = [\"red\" if c < 0 else \"blue\" for c in coef[interesting_coefficients]]\n",
    "    plt.bar(np.arange(2 * n_top_features), coef[interesting_coefficients], color=colors)\n",
    "    feature_names = np.array(feature_names)\n",
    "    plt.xticks(np.arange(1, 1 + 2 * n_top_features), feature_names[interesting_coefficients], rotation=60, ha=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_grid_scores(grid, param_name):\n",
    "    plt.plot(grid.param_grid[param_name], grid.cv_results_['mean_train_score'],\n",
    "        color='green', label='train')\n",
    "    plt.plot(grid.param_grid[param_name], grid.cv_results_['mean_test_score'],\n",
    "        color='red', label='test')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "visualize_coefficients(logit, cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Підберемо коефіцієнт регуляризації для логістичної регресії. Використовуємо `sklearn.pipeline`, оскільки` CountVectorizer` правильно застосовувати тільки за тими даними, за якими в поточний момент навчається модель (щоб не \"підглядати\" в тестову вибірку і не брати до уваги по ній частоти входження слів). В даному випадку `pipeline` задає послідовність дій: застосувати` CountVectorizer`, потім навчити логістичну регресію."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "text_pipe_logit = make_pipeline(CountVectorizer(), \n",
    "                                LogisticRegression(n_jobs=-1, random_state=7))\n",
    "\n",
    "text_pipe_logit.fit(text_train, y_train)\n",
    "print(text_pipe_logit.score(text_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_logit = {'logisticregression__C': np.logspace(-5, 0, 6)}\n",
    "grid_logit = GridSearchCV(text_pipe_logit, param_grid_logit, cv=3, n_jobs=-1, return_train_score=True)\n",
    "\n",
    "grid_logit.fit(text_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Краще значення C і відповідна якість на крос-валідації:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "grid_logit.best_params_, grid_logit.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "plot_grid_scores(grid_logit, 'logisticregression__C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "За валідаційною вибіркою:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "grid_logit.score(text_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Тепер те ж саме, але з випадковим лісом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "round(forest.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Відповідно результатів вище бачимо, що з використанням логістичної регресії ми досягли більшої частки правильних відповідей з меншими зусиллями (0.855 < 0.879)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"4.4.3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### <span style=\"color:blue; font-size:1.2em;\">4.4.3. XOR-проблема</span>\n",
    "\n",
    "[Повернутися до змісту](#4-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Тепер розглянемо приклад, де лінійні моделі справляються гірше.\n",
    "\n",
    "Лінійні методи класифікації будують все ж дуже просту розділяючу поверхню – гіперплощину. Найвідоміший іграшковий приклад, в якому класи можна без помилок розділити гіперплощиною (тобто прямою, якщо це 2D), отримав назву \"the XOR problem\". XOR – це \"виключне АБО\", булева функція з такою таблицею істинності:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![img](https://raw.githubusercontent.com/radiukpavlo/intelligent-data-analysis/main/03_img/4_2_11_XOR_table.gif)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "XOR дав назву простій задачі бінарної класифікації, в якій класи подано множинами точок, що перетинаються і є витягнутими за діагоналями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# створюємо дані\n",
    "rng = np.random.RandomState(0)\n",
    "X = rng.randn(200, 2)\n",
    "y = np.logical_xor(X[:, 0] > 0, X[:, 1] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "plt.scatter(X[:, 0], X[:, 1], s=30, c=y, cmap=plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Очевидно, не можна провести пряму так, щоб без помилок відокремити один клас від іншого. Тому логістична регресія погано справляється з такою задачею."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def plot_boundary(clf, X, y, plot_title):\n",
    "    \n",
    "    xx, yy = np.meshgrid(np.linspace(-3, 3, 50),\n",
    "                     np.linspace(-3, 3, 50))\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    # відобразимо функцію рішення для кожної точки на координатній площині\n",
    "    Z = clf.predict_proba(np.vstack((xx.ravel(), yy.ravel())).T)[:, 1]\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    image = plt.imshow(Z, interpolation='nearest',\n",
    "                           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "                           aspect='auto', origin='lower', cmap=plt.cm.PuOr_r)\n",
    "    contours = plt.contour(xx, yy, Z, levels=[0], linewidths=2,\n",
    "                               linetypes='--')\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=30, c=y, cmap=plt.cm.Paired)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.xlabel(r'$x_1$')\n",
    "    plt.ylabel(r'$x_2$')\n",
    "    plt.axis([-3, 3, -3, 3])\n",
    "    plt.colorbar(image)\n",
    "    plt.title(plot_title, fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "plot_boundary(LogisticRegression(), X, y,\n",
    "              \"Логістична регресія, XOR problem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "А ось якщо на вхід подати поліноміальні ознаки, в даному випадку до степеня 2, то задача розв'язується."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "logit_pipe = Pipeline([('poly', PolynomialFeatures(degree=2)), \n",
    "                       ('logit', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "plot_boundary(logit_pipe, X, y,\n",
    "              \"Логістична регресія + квадратичні ознаки. XOR problem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Тут логістична регресія все одно будувала гіперплощину, але в 6-вимірному просторі ознак $1, x_1, x_2, x_1^2, x_1x_2$ и $x_2^2$. У проекції на початковий простір ознак $x_1, x_2$ границю вийшла нелінійна.\n",
    "\n",
    "На практиці поліноміальні ознаки дійсно допомагають, але будувати їх явно – обчислювально неефективно. Набагато швидше працює метод опорних векторів з ядровим трюком. За такого підходу в просторі високої розмірності обраховується тільки відстань між об'єктами (що задається функцією-ядром), а явно створювати комбінаторно велику кількість ознак не потрібно. З цим питанням можна детальніше ознайомитися в курсі Євгенія Соколова – [тут](https://github.com/esokolov/ml-course-msu/blob/master/ML16/lecture-notes/Sem10_linear.pdf) (математика вже серйозна)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"4.5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <span style=\"color:blue; font-size:1.2em;\">4.5. Криві валідації й навчання</span>\n",
    "\n",
    "[Повернутися до змісту](#4-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.model_selection import validation_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"4.5.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### <span style=\"color:blue; font-size:1.2em;\">4.5.1. Як покращити модель?</span>\n",
    "\n",
    "[Повернутися до змісту](#4-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ми вже маємо уявлення щодо перевірки моделі, крос-валідації та регуляризації.\n",
    "Тепер розглянемо головне питання:\n",
    "\n",
    "**Якщо якість моделі нас не влаштовує, то що робити?**\n",
    "\n",
    "- Зробити модель складнішою чи, навпаки, спростити?\n",
    "- Додати більше ознак?\n",
    "- Чи потрібно додати більше даних для навчання?\n",
    "\n",
    "Відповіді на ці питання не завжди лежать на поверхні. Зокрема, іноді використання більш складної моделі призведе до погіршення показників. Або додавання спостережень не призведе до відчутних змін. Здатність прийняти правильне рішення й вибрати правильний спосіб поліпшення моделі, власне кажучи, і відрізняє хорошого фахівця від поганого."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Будемо працювати з уже знайомими даними щодо відтоку клієнтів телеком-оператора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "telecom_churn_url = 'https://raw.githubusercontent.com/radiukpavlo/intelligent-data-analysis/main/01_lecture-notes/ida_lecture-04_linear_models/telecom_churn.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data_telchurn = pd.read_csv(telecom_churn_url).drop('State', axis=1)\n",
    "\n",
    "data_telchurn['International plan'] = data_telchurn['International plan'].map({'Yes': 1, 'No': 0})\n",
    "data_telchurn['Voice mail plan'] = data_telchurn['Voice mail plan'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "y_telchurn = data_telchurn['Churn'].astype('int').values\n",
    "X_telchurn = data_telchurn.drop('Churn', axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Тут будемо навчати логістичну регресію за допомогою стохастичного градієнтного спуску. Наразі так швидше. Але в подальшому стохастичному градієнтному спуску буде присвячена окрема тема. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "alphas = np.logspace(-2, 0, 20)\n",
    "sgd_logit = SGDClassifier(loss='log', n_jobs=-1, random_state=17, max_iter=5)\n",
    "logit_pipe = Pipeline([('scaler', StandardScaler()), ('poly', PolynomialFeatures(degree=2)),\n",
    "                       ('sgd_logit', sgd_logit)])\n",
    "val_train, val_test = validation_curve(logit_pipe, X_telchurn, y_telchurn,\n",
    "                                       param_name='sgd_logit__alpha', param_range=alphas, cv=5,\n",
    "                                       scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Побудуємо валідаційні криві, що показують, як якість (ROC AUC) за навчальною та валідаційною вибірками змінюється зі зміною параметра регуляризації."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def plot_with_err(x, data, **kwargs):\n",
    "    mu, std = data.mean(1), data.std(1)\n",
    "    lines = plt.plot(x, mu, '-', **kwargs)\n",
    "    plt.fill_between(x, mu - std, mu + std, edgecolor='none',\n",
    "                     facecolor=lines[0].get_color(), alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "plot_with_err(alphas, val_train, label='training scores')\n",
    "plot_with_err(alphas, val_test, label='validation scores')\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Тенденцію видно відразу, і вона дуже часто зустрічається.\n",
    "\n",
    "1. Для простих моделей навчальна та валідаційна помилка перебувають приблизно поруч, і вони великі. Це говорить про те, що модель *недонавчилась*: тобто вона не має достатню кількість параметрів.\n",
    "\n",
    "2. Для сильно ускладнених моделей навчальна та валідаційна помилки значно відрізняються. Це можна пояснити *перенавчанням*: коли параметрів занадто багато або не вистачає регуляризації, алгоритм може \"відволікатися\" на шум в даних й не враховувати упускати основний тренд."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"4.5.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### <span style=\"color:blue; font-size:1.2em;\">4.5.2. Скільки потрібно даних?</span>\n",
    "\n",
    "[Повернутися до змісту](#4-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Відомо, що чим більше даних використовує модель, тим краще. Але як нам зрозуміти в конкретній ситуації, чи допоможуть нові дані? Скажімо, чи доцільно нам витратити \\$ N на роботу асесорів, щоб збільшити вибірку вдвічі?\n",
    "\n",
    "Оскільки нових даних поки може і не бути, розумно змінювати розмір наявної навчальної вибірки та дивитися, як якість розв'язку задачі залежить від обсягу даних, за якими ми навчали модель. У такий спосіб отримують *криві навчання* (*learning curves*).\n",
    "\n",
    "Ідея проста: ми відображаємо помилку, як функцію від кількості прикладів, що використовуються для навчання. Водночас параметри моделі фіксуються заздалегідь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(degree=2, alpha=0.01):\n",
    "    train_sizes = np.linspace(0.05, 1, 20)\n",
    "    logit_pipe = Pipeline([('scaler', StandardScaler()), ('poly', PolynomialFeatures(degree=degree)), \n",
    "                           ('sgd_logit', SGDClassifier(n_jobs=-1, random_state=17, alpha=alpha))])\n",
    "    N_train, val_train, val_test = learning_curve(logit_pipe,\n",
    "                                                  X, y, train_sizes=train_sizes, cv=5,\n",
    "                                                  scoring='roc_auc')\n",
    "    plt.figure(figsize=(7,5), dpi=100)\n",
    "    plot_with_err(N_train, val_train, label='training scores')\n",
    "    plot_with_err(N_train, val_test, label='validation scores')\n",
    "    plt.xlabel('Training Set Size')\n",
    "    plt.ylabel('AUC')\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Давайте глянемо, що ми отримаємо для лінійної моделі. Коефіцієнт регуляризації поставимо великим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(degree=2, alpha=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Типова ситуація: для невеликого обсягу даних помилки за навчальною вибіркою й в процесі крос-валідації досить сильно відрізняються, що вказує на перенавчання. Для тієї ж моделі, але з великим об'ємом даних помилки \"збігаються\", що вказує на недонавчання.\n",
    "\n",
    "Якщо додати ще дані, то помилка за навчальною вибіркою не буде рости, але з іншого боку, помилка за тестовими даними не буде зменшуватися.\n",
    "\n",
    "Виходить, що помилки \"зійшлися\", і додавання нових даних не допоможе. Зокрема цей випадок – найцікавіший з точки зору бізнесу. Можлива ситуація, коли ми збільшуємо вибірку в 10 разів. Але якщо не міняти складність моделі, це може і не допомогти. Тобто стратегія \"налаштував один раз м далі використовую 10 раз\" може і не працювати.\n",
    "\n",
    "Що буде, якщо змінити коефіцієнт регуляризації?\n",
    "Бачимо хорошу тенденцію – криві поступово збігаються, і якщо далі рухатися вправо (додавати в модель дані), можна ще підвищити якість за валідаційними даними."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(degree=2, alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "А якщо ускладнити ще більше?\n",
    "\n",
    "Проявляється перенавчання – AUC падає як під час навчання, так і під час валідації."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(degree=2, alpha=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Будуючи подібні криві, можна зрозуміти, куди рухатися, і як правильно налаштувати складність моделі за новими даними."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"4.6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <span style=\"color:blue; font-size:1.2em;\">Висновки</span>\n",
    "\n",
    "[Повернутися до змісту](#4-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Помилка за навчальною вибіркою сама по собі нічого не говорить щодо якості моделі.\n",
    "2. Крос-валідаційна помилка показує, наскільки добре модель підлаштовується під дані (наявний тренд в даних), зберігаючи при цьому здатність узагальнення за новими даними.\n",
    "3. *Валідаційна крива* – це графік, який показує результат за навчальною та валідаційною вибірками залежно від *складності моделі*:\n",
    "   - якщо дві криві розташовуються близько одна до дної, а обидві помилки великі – це ознака *недонавчання*;\n",
    "   - Якщо дві криві далеко одна від одної – це індикатор *перенавчання*.\n",
    "4. *Крива навчання* – це графік, який показує результати за навчальною та валідаційною вибірками залежно від кількості спостережень:\n",
    "   - якщо криві збіглися одна до одної, додавання нових даних не допоможе – треба міняти складність моделі;\n",
    "   - якщо криві не зійшлися, додавання нових даних може поліпшити результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
