{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Лабораторна робота 7.</center></h1>\n",
    "<h2><center>Аналіз активності людини за відкритими даними мобільних телефонів</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Виконав:** Прізвище І.П.\n",
    "\n",
    "**Варіант:** №__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"lab-7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Зміст\n",
    "\n",
    "- [7.1. Завантаження та підготовка даних](#lab-7.1)\n",
    "- [7.2. Застосування методу головних компонент](#lab-7.2)  \n",
    "- [7.3. Застосування *k*-means](#lab-7.3)\n",
    "- [7.4. Агломератична кластеризація](#lab-7.4)\n",
    "- [7.5. Застосування класифікатора після кластеризації](#lab-7.5)\n",
    "- [7.6. Класифікація із пониженням розмірності](#lab-7.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"lab-7.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue; font-size:1.2em;\">7.1. Завантаження та підготовка даних</span>\n",
    "\n",
    "[Повернутися до змісту](#lab-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У цій лабораторній робота Вам потрібно розібратися з тим, як працюють методи пониження розмірності й кластеризації даних. Крім того, ще раз попрактикуємося із задачею класифікації.\n",
    "\n",
    "Тут ми працюватимемо з набором даних [Human Activity Recognition with Smartphones](https://www.kaggle.com/datasets/uciml/human-activity-recognition-with-smartphones). Завантажте дані (чотири файли у форматі .txt) з [репозиторію](https://github.com/radiukpavlo/intelligent-data-analysis/tree/main/02_assignments/ida_lab-07_pca-kmeans/samsung_HAR) на GitHub.\n",
    "\n",
    "Дані взято з акселерометрів і гіроскопів мобільних телефонів Samsung Galaxy S3 (докладніше щодо ознак – за посиланням на UCI вище), також відомий вид активності людини з телефоном в кишені – чи ходила людина, стояла, лежала, сиділа або йшла вгору/вниз сходами.\n",
    "\n",
    "Спершу представимо, що вид активності нам невідомий, і спробуємо кластеризувати людей лише на основі наявних свідчень. Далі розв'яжемо завдання визначення виду фізичної активності саме як задачу класифікації."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T14:39:39.710232500Z",
     "start_time": "2023-12-15T14:39:39.648668800Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radiu\\AppData\\Local\\Temp\\ipykernel_33000\\3543394545.py:9: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use(['seaborn-darkgrid'])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use(['seaborn-darkgrid'])\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "RANDOM_STATE = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T14:39:40.735628500Z",
     "start_time": "2023-12-15T14:39:39.714739900Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Завантаження даних, якщо код пишеться в редакторі з Anaconda\n",
    "X_train = np.loadtxt(\"./samsung_HAR/samsung_train.txt\")\n",
    "y_train = np.loadtxt(\"./samsung_HAR/samsung_train_labels.txt\").astype(int)\n",
    "\n",
    "X_test = np.loadtxt(\"./samsung_HAR/samsung_test.txt\")\n",
    "y_test = np.loadtxt(\"./samsung_HAR/samsung_test_labels.txt\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T14:39:40.786680600Z",
     "start_time": "2023-12-15T14:39:40.750774200Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Перевіримо розмірності\n",
    "assert(X_train.shape == (7352, 561) and y_train.shape == (7352,))\n",
    "assert(X_test.shape == (2947, 561) and y_test.shape == (2947,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для кластеризації нам не потрібен вектор відповідей, тому будемо працювати з об'єднанням навчальної та тестової вибірок. Об'єднаємо `X_train` з `X_test` та `y_train` з `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T14:39:40.820012300Z",
     "start_time": "2023-12-15T14:39:40.767649900Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = np.vstack([X_train, X_test])\n",
    "y = np.hstack([y_train, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визначимо кількість унікальних значень міток цільового класу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T14:39:40.870561600Z",
     "start_time": "2023-12-15T14:39:40.796994300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T14:39:40.891389100Z",
     "start_time": "2023-12-15T14:39:40.860145900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = np.unique(y).size\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ці мітки [відповідають](https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.names) таким значенням:\n",
    "- 1 – ходьба;\n",
    "- 2 – підйом вгору сходами;\n",
    "- 3 – спуску вниз сходами;\n",
    "- 4 – сидіння;\n",
    "- 5 – стояння;\n",
    "- 6 – лежання."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Виконаємо масштабування вибірки за допомогою `StandardScaler` з параметрами за замовчуванням:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T14:39:41.012682800Z",
     "start_time": "2023-12-15T14:39:40.875874100Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"lab-7.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue; font-size:1.2em;\">7.2. Застосування методу головних компонент</span>\n",
    "\n",
    "[Повернутися до змісту](#lab-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red; font-size:1.5em;\">Завдання 1</span>\n",
    "\n",
    "\n",
    "**Для всіх варіантів:**\n",
    "\n",
    "**Виконайте пониження розмірності даних за допомогою PCA. Залишіть таку кількість компонент, щоби пояснити як мінімум 90% дисперсії оброблених (масштабованих) даних. Використайте масштабовану вибірку й зафіксуйте random_state (константа RANDOM_STATE).**\n",
    "\n",
    "**Для варіантів 1–2:**\n",
    "\n",
    "Застосуйте інкрементний PCA (`sklearn.decomposition.IncrementalPCA`) до вхідного набору даних, щоб ефективно керувати використанням пам’яті. Порівняйте результати зі стандартним PCA з погляду поясненої дисперсії та ефективності кластеризації за допомогою k-середніх. Обговоріть компроміси між інкрементним та звичайним PCA.\n",
    "\n",
    "**Для варіантів 3–4:**\n",
    "\n",
    "Використайте ядерний PCA (`sklearn.decomposition.KernelPCA`) з різними ядрами, такими як радіально-базисна функція (RBF), поліноміальна та сигмоїдна. Проаналізуйте, як вибір ядра впливає на результати кластеризації, і візуалізуйте дані в зменшеному просторі. Наведіть приклади, за яких Kernel PCA може бути більш вигідним, ніж стандартний PCA.\n",
    "\n",
    "**Для варіантів 5–6:**\n",
    "\n",
    "Застосуйте розріджений PCA (`sklearn.decomposition.SparsePCA`), щоб зменшити розрідженість компонентів, що полегшить їх інтерпретацію. Порівняйте його ефективність зі звичайним PCA з погляду ефективності кластеризації та інтерпретації компонентів. Обговоріть важливість розрідженості компонентів PCA в контексті розпізнавання людської діяльності.\n",
    "\n",
    "**Для варіантів 7–8:**\n",
    "\n",
    "Проведіть експерименти з різною кількістю компонентів в PCA (`sklearn.decomposition.PCA`) і проаналізуйте, як це впливає на ефективність кластеризації, використовуючи такі метрики, як оцінка силуету. Обговоріть концепцію «методу ліктя» при визначенні оптимальної кількості компонент.\n",
    "\n",
    "**Для варіантів 9–10:**\n",
    "\n",
    "Порівняйте PCA з лінійним дискримінантним аналізом (`sklearn.discriminant_analysis.LinearDiscriminantAnalysis`) для зменшення розмірності. Оцініть та порівняйте їх ефективність у задачах кластеризації та класифікації за відповідними метриками, обговоривши відмінності між підходами PCA (некерованим) та LDA (керованим).\n",
    "\n",
    "**Для варіантів 11–12:**\n",
    "\n",
    "Використайте PCA, щоб звести набір даних до трьох вимірів і візуалізувати кластери за допомогою діаграми розсіювання (scatter plot). Продемонструйте як різні види діяльності розділені в зменшеному просторі та визначте чи допомагає PCA виявити чіткі закономірності або відмінності між різними видами діяльності.\n",
    "\n",
    "**Для варіантів 13–14:**\n",
    "\n",
    "Застосуйте PCA з обертанням Varimax для отримання більш інтерпретованої структури з більш чіткими навантаженнями на ознаки. Обговоріть, як ротація впливає на інтерпретацію головних компонент та її корисність у розвідувальному аналізі.\n",
    "\n",
    "**Для варіантів 15–16:**\n",
    "\n",
    "Поєднайте PCA з методами відбору ознак, такими як SelectKBest та SelectPercentile (`sklearn.feature_selection`). Проведіть експерименти щодо того, як така комбінація впливає на продуктивність алгоритмів кластеризації та класифікації, й обговоріть баланс між відбором ознак і зменшенням розмірності.\n",
    "\n",
    "**Для варіантів 17–18:**\n",
    "\n",
    "Застосуйте PCA окремо до різних підмножин даних (наприклад, на основі різних видів діяльності) і порівняйте результати. Проаналізуйте як працює PCA на однорідних і неоднорідних підмножинах даних і які наслідки це має для розпізнавання активності.\n",
    "\n",
    "**Для варіантів 19–20:**\n",
    "\n",
    "Яку мінімальну кількість головних компонент потрібно виділити, щоб пояснити 90% дисперсії початкових (масштабованих) даних? Виведіть номер головної компоненти, на яку припадає найбільший % дисперсії (для 90% дисперсії). Скільки відсотків дисперсії припадає на першу головну компоненту?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"lab-7.3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue; font-size:1.2em;\">7.3. Застосування *k*-means</span>\n",
    "\n",
    "[Повернутися до змісту](#lab-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Виконайте кластеризацію даних методом `Kmeans`, навчивши модель за даними зі зниженою за рахунок PCA розмірністю. Тут потрібно шукати саме 6 кластерів, але загалом у задачах без вчителя ми не знаємо, яку кількість кластерів треба шукати.\n",
    "\n",
    "Параметри:\n",
    "\n",
    "- **n_clusters** = n_classes (кількість унікальних міток цільового класу);\n",
    "- **n_init** = 100;\n",
    "- **random_state** = RANDOM_STATE (для відтворюваності результату).\n",
    "\n",
    "Інші параметри залишаються за замовчуванням."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red; font-size:1.5em;\">Завдання 2</span>\n",
    "\n",
    "\n",
    "**Для варіантів 1–2:**\n",
    "\n",
    "Побудуйте нові моделі на основі інших методів ініціалізації k-середніх (наприклад, k-means++, random) у `sklearn.cluster.KMeans`. Визначте, як ініціалізація впливає на кінцевий результат за метриками кластеризації та швидкість збіжності (convergence).\n",
    "\n",
    "**Для варіантів 3–4:**\n",
    "\n",
    "Змінюйте кількість кластерів у k-середніх та проведіть оцінювання результати кластеризації за допомогою таких метрик, як Silhouette Score та Davies-Bouldin index. Визначте оптимальну кількість кластерів та оцініть вплив цього значення на результат кластеризації.\n",
    "\n",
    "**Для варіантів 5–6:**\n",
    "\n",
    "Порівняйте продуктивність і обчислювальну ефективність k-середніх з Mini Batch K-means (`sklearn.cluster.MiniBatchKMeans`). Проведіть експерименти зі сценаріями, за яких Mini Batch K-means є кращим за стандартні k-means, особливо з точки зору масштабованості та часу обчислень.\n",
    "\n",
    "**Для варіантів 7–8:**\n",
    "\n",
    "Виконайте кластеризацію k-середніх за даними, розмірність яких була понижена за допомогою tSNE. Порівняйте результати кластеризації з k-середніми, що виконана за повним набором даних. Поясніть, як зменшення розмірності впливає на результат кластеризації.\n",
    "\n",
    "**Для варіантів 9–10:**\n",
    "\n",
    "Проведіть експерименти з різними метриками відстані в k-середніх (euclidean, squared euclidean, manhattan, chebyshev, canberra, chi-square) та проаналізуйте їхній вплив на результати кластеризації. Поясніть придатність кожної метрики для даного набору даних і характеру даних про людську діяльність.\n",
    "\n",
    "**Для варіантів 11–12:**\n",
    "\n",
    "Використайте k-середні для виявлення аномалій у наборі даних. Визначте, як кластеризація може бути використана для виявлення аномалій, а також запропонуйте шляхи розв'язання проблем, що пов'язані з використанням k-середніх для цього завдання.\n",
    "\n",
    "**Для варіантів 13–14:**\n",
    "\n",
    "Реалізувати версію k-середніх, яка дає змогу зважувати ознаки (feature weighting), підкреслюючи певні ознаки більше, ніж інші. Визначте, як зважування ознак впливає на результати кластеризації та його потенційні переваги для розпізнавання активності.\n",
    "\n",
    "**Для варіантів 15–16:**\n",
    "\n",
    "Проведіть експерименти з різними критеріями збіжності k-середніх (change in inertia, maximum number of iterations) і проаналізуйте їхній вплив на кінцевий результат кластеризації та продуктивність алгоритму. Обґрунтуйте важливість встановлення відповідних критеріїв збіжності в k-середніх.\n",
    "\n",
    "**Для варіантів 17–18:**\n",
    "\n",
    "Використайте різні метрики (Adjusted Rand Index, Adjusted Mutual Information, Silhouette) для оцінювання якості кластеризації за методом k-середніх. Порівняйте результати кластеризації з істинними мітками (true labels), щоб оцінити продуктивність і проаналізуйте обмеження використання зовнішньої валідації в неконтрольованому навчанні.\n",
    "\n",
    "**Для варіантів 19–20:**\n",
    "\n",
    "Застосуйте метод k-середніх до ознак, що перетворені за допомогою методів Box-Cox та Yeo-Johnson (`sklearn.preprocessing`). Визначте, як різні перетворення впливають на результати кластеризації та важливість вибору відповідних перетворень для набору даних.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"lab-7.4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue; font-size:1.2em;\">7.4. Агломератична кластеризація</span>\n",
    "\n",
    "[Повернутися до змісту](#lab-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спробуємо ще один алгоритм, що входить до групи ієрархічної кластеризації – агломеративну кластеризацію [`AgglomerativeClustering()`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red; font-size:1.5em;\">Завдання 3</span>\n",
    "\n",
    "\n",
    "**Для варіантів 1–2:**\n",
    "\n",
    "Проведіть експерименти з різними критеріями зв’язку в Агломеративній кластеризації (`sklearn.cluster.AgglomerativeClustering`), такими як Ward, complete, average, та single linkage. Визначте, як кожен критерій впливає на структуру кластеризації, особливо в контексті набору даних про людську діяльність.\n",
    "\n",
    "**Для варіантів 3–4:**\n",
    "\n",
    "Виконайте Агломеративну кластеризацію за даними, що попередньо оброблені за допомогою PCA та t-SNE. Визначте, як методи зменшення розмірності впливають на результати кластеризації та їхню корисність для виявлення прихованих закономірностей у даних.\n",
    "\n",
    "**Для варіантів 5–6:**\n",
    "\n",
    "Реалізуйте схему перехресної перевірки (cross-validation) для оцінки стабільності результатів Агломеративної кластеризації. Проаналізуйте методологію застосування перехресної перевірки в контексті навчання без учителя.\n",
    "\n",
    "**Для варіантів 7–8:**\n",
    "\n",
    "Включіть в Агломеративну кластеризацію обмеження зв’язності на основі k-найближчих сусідів. Визначте, як введення цих обмежень впливає на форму й розмір кластерів та загальну ефективність кластеризації.\n",
    "\n",
    "**Для варіантів 9–10:**\n",
    "\n",
    "Реалізуйте дендрограми (dendrograms) для результатів Агломеративної кластеризації та використайте їх для дослідження ієрархічної структури кластерів. Визначте, як аналіз дендрограми може допомогти у виборі оптимальної кількості кластерів і яку інформацію він надає про дані.\n",
    "\n",
    "**Для варіантів 11–12:**\n",
    "\n",
    "Використайте кластери, сформовані Агломеративною кластеризацією, як ознаки в моделі навчання з учителем (supervised learning model). Визначте, як цей підхід може підвищити продуктивність моделі та надати уявлення про взаємозв’язки між ознаками.\n",
    "\n",
    "**Для варіантів 13–14:**\n",
    "\n",
    "Обрахуйте Adjusted Rand Index для розбиття на два кластери за AgglomerativeClustering та MiniBatchKmeans з параметрами із пункту 7.3. Порівняйте значення ARI, знайденого для AgglomerativeClustering та MiniBatchKmeans.\n",
    "\n",
    "**Для варіантів 15–16:**\n",
    "\n",
    "Застосуйте різні методи нормалізації (StandardScaler, MinMaxScaler та RobustScaler) до набору даних перед виконанням Агломеративної кластеризації. Оцініть за метриками кластеризації (див. лекційну записку 7), як нормалізація впливає на результати кластеризації, й проаналізуйте важливість нормалізації ознак в ієрархічній кластеризації.\n",
    "\n",
    "**Для варіантів 17–18:**\n",
    "\n",
    "Використайте індекси валідності кластерів, такі як silhouette score, Calinski-Harabasz index, and Davies-Bouldin index, для оцінки якості кластерів, сформованих Агломеративною кластеризацією. Визначте переваги та обмеження цих індексів в оцінці якості кластеризації.\n",
    "\n",
    "**Для варіантів 19–20:**\n",
    "\n",
    "Проведіть експерименти з різними метриками відстані (euclidean, squared euclidean, manhattan, chebyshev, canberra, chi-square) в Агломеративній кластеризації. Проаналізуйте вплив цих метрик на результат кластеризації, особливо для розуміння людської діяльності.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"lab-7.5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue; font-size:1.2em;\">7.5. Застосування класифікатора після кластеризації</span>\n",
    "\n",
    "[Повернутися до змісту](#lab-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Варто відзначити, що попереднє завдання не надто добре розв'язується саме як задача кластеризації, якщо виділяти лише кілька кластерів (>2). Спробуємо тепер розв'яжемо задачу класифікації; пам'ятаємо, що дані у нас розмічені."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red; font-size:1.5em;\">Завдання 4</span>\n",
    "\n",
    "\n",
    "**Для варіантів 1–2:**\n",
    "\n",
    "Застосуйте різні класифікатори (SVM, Random Forest, Logistic Regression) до кластеризованих даних та порівняйте їхню ефективність. Проаналізуйте, як кластеризація як етап попередньої обробки впливає на точність класифікації та складність моделі.\n",
    "\n",
    "**Для варіантів 3–4:**\n",
    "\n",
    "Використайте деревовидні класифікатори, як от випадковий ліс та беггінг дерев ріщень після кластеризації для оцінювання важливості ознак. Проаналізуйте, як кластеризація впливає на важливість різних ознак у задачі класифікації.\n",
    "\n",
    "**Для варіантів 5–6:**\n",
    "\n",
    "Налаштуйте для `sklearn.svm.LinearSVC` гіперпараметри за допомогою `GridSearchCV` (cv=3). Виконайте навчання нового `StandardScaler` за навчальною вибіркою (з усіма початковими ознаками), застосуйте масштабування до тестової вибірки. Який вид активності LinearSVC визначає найгірше за метрикою $F_1$-score? Виведіть назву відповідної ознаки (вид активності) та значення відповідної метрики за допомогою коду.\n",
    "\n",
    "**Для варіантів 7–8:**\n",
    "\n",
    "Використайте `sklearn.model_selection.GridSearchCV` для налаштування гіперпараметрів класифікатора `sklearn.svm.LinearSVC`, застосованого після кластеризації. Проаналізуйте вплив кластеризації на оптимальні налаштування гіперпараметрів і продуктивність моделі.\n",
    "\n",
    "**Для варіантів 9–10:**\n",
    "\n",
    "Розгляньте мітки кластерів як нові ознаки та додайте їх до початкового набору ознак. Обрахуйте частку правильних відповідей (accuracy) класифікатора `sklearn.svm.LinearSVC`? Виведіть значення відповідної метрики за допомогою коду. Оцініть за метриками класифікації (accuracy, precision, recall, $F_1$-score, ROC-AUC), як така форма інженерії ознак впливає на продуктивність різних класифікаторів.\n",
    "\n",
    "**Для варіантів 11–12:**\n",
    "\n",
    "Проведіть експерименти з ансамблевими моделями та дослідіть різні метрики оцінювання (accuracy, precision, recall, $F_1$-score, ROC-AUC) для класифікаторів, застосованих після кластеризації. Проаналізуйте, як кластеризація впливає на ці метрики та наслідки для оцінки моделі.\n",
    "\n",
    "**Для варіантів 13–14:**\n",
    "\n",
    "Порівняйте продуктивність класифікатора `sklearn.svm.LinearSVC`, застосованого до даних, що кластеризовані за допомогою різних алгоритмів (k-середніх, агломеративної кластеризації, DBSCAN). Виведіть та проаналізуйте результати класифікації за допомогою classification_report.\n",
    "\n",
    "**Для варіантів 15–16:**\n",
    "\n",
    "Застосуйте методи зменшення розмірності (PCA, LDA та t-SNE) перед класифікацією та оцініть за метриками класифікації (accuracy, precision, recall, $F_1$-score, ROC-AUC), як така попередня обробка впливає на продуктивність класифікатора. Обговоріть переваги та недоліки зменшення розмірності в контексті кластеризованих даних.\n",
    "\n",
    "**Для варіантів 17–18:**\n",
    "\n",
    "Реалізуйте ансамбль стекування (`sklearn.ensemble.StackingClassifier`) з використанням різних базових класифікаторів за кластеризованими даними. Проаналізуйте продуктивність стекової моделі та обговоріть синергетичні ефекти поєднання декількох класифікаторів у цьому контексті.\n",
    "\n",
    "**Для варіантів 19–20:**\n",
    "\n",
    "Застосуйте ансамблеві методи (Gradient Boosting та AdaBoost з `sklearn.ensemble`) за кластеризованими даними. Оцініть за метриками класифікації (accuracy, precision, recall, $F_1$-score, ROC-AUC), як ансамблеві методи працюють у порівнянні з простими моделями (k-nearist neighbors та logistic regression) та роль кластеризації в покращенні роботи ансамблю."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"lab-7.6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue; font-size:1.2em;\">7.6. Класифікація із пониженням розмірності</span>\n",
    "\n",
    "[Повернутися до змісту](#lab-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red; font-size:1.5em;\">Завдання 5</span>\n",
    "\n",
    "\n",
    "**Для варіантів 1–2:**\n",
    "\n",
    "Поєднайте метод PCA з методом вибору ознак, наприклад, SelectFromModel (`sklearn.feature_selection.SelectFromModel`), використовуючи SVM-класифікатор. Оцініть за метриками класифікації (accuracy, precision, recall, $F_1$-score, ROC-AUC), як ця комбінація впливає на ефективність класифікації та визначте баланс між зменшенням розмірності та важливістю ознак.\n",
    "\n",
    "**Для варіантів 3–4:**\n",
    "\n",
    "Застосуйте попередню обробку методом PCA перед використанням ансамблевих класифікаторів RandomForest та GradientBoosting (`sklearn.ensemble`). Оцініть за метриками класифікації (accuracy, precision, recall, $F_1$-score, ROC-AUC) вплив PCA на продуктивність ансамблевих класифікаторів та проаналізуйте, як PCA може потенційно покращити ансамблеве навчання.\n",
    "\n",
    "**Для варіантів 5–6:**\n",
    "\n",
    "Використайте ядерний PCA (decomposition.KernelPCA) як частину конвеєра (`sklearn.pipeline.Pipeline`) і виконайте налаштування гіперпараметрів за допомогою GridSearchCV (`sklearn.model_selection.GridSearchCV`). Проаналізуйте, як зменшений простір ознак впливає на оптимальні значення гіперпараметрів і продуктивність класифікатора.\n",
    "\n",
    "**Для варіантів 7–8:**\n",
    "\n",
    "Проведіть експерименти з PCA, зберігаючи різні рівні дисперсії (90%, 95% і 99%), і проаналізуйте, як цей вибір впливає на продуктивність класифікатора. Зробіть висновки щодо компромісів між зменшенням розмірності та збереженням інформації.\n",
    "\n",
    "**Для варіантів 9–10:**\n",
    "\n",
    "Застосуйте нелінійні класифікатори k-nearist neighbors та SVM після застосування PCA. Оцініть за метриками класифікації (accuracy, precision, recall, $F_1$-score, ROC-AUC), як PCA впливає на продуктивність нелінійних моделей та проаналізуйте взаємодію між лінійним зменшенням розмірності та нелінійною класифікацією.\n",
    "\n",
    "**Для варіантів 11–12:**\n",
    "\n",
    "Поєднайте з методами вирівнювання дисбалансу класів [`imblearn.over_sampling.SMOTE`](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html) та class weight adjustment. Оцініть за метриками класифікації (accuracy, precision, recall, $F_1$-score, ROC-AUC), як ці методи впливають на продуктивність класифікатора на даних, перетворених методом PCA, і проаналізуйте проблеми обробки дисбалансу класів у просторах зі зменшеною розмірністю.\n",
    "\n",
    "**Для варіантів 13–14:**\n",
    "\n",
    "Використайте метод PCA, а потім класифікатор k-nearist neighbors з різними метриками відстані (euclidean, squared euclidean, manhattan, chebyshev, minkowski, and chi-square). Дослідіть, як PCA впливає на ефективність різних метрик відстані в класифікаторі KNN.\n",
    "\n",
    "**Для варіантів 15–16:**\n",
    "\n",
    "Застосуйте різні методи масштабування (StandardScaler, MinMaxScaler, and RobustScaler) перед PCA та оцініть за метриками класифікації (accuracy, precision, recall, $F_1$-score, ROC-AUC) їхній вплив на роботу класифікатора випадкового лісу.\n",
    "\n",
    "**Для варіантів 17–18:**\n",
    "\n",
    "Застосуйте `decomposition.TruncatedSVD` до початкових даних перед застосуванням беггінгу логістичної регресії з різним типом регуляризації (L1 та L2). Проаналізуйте, як регуляризація взаємодіє зі зменшеним простором ознак, створеним за допомогою PCA.\n",
    "\n",
    "**Для варіантів 19–20:**\n",
    "\n",
    "Використайте ансамблевий класифікатор беггінгу логістичної регресії зі стекуванням (`sklearn.ensemble.StackingClassifier`), де кожна базова модель навчається на різній кількості компонентів PCA. Оцініть за метриками класифікації (accuracy, precision, recall, $F_1$-score, ROC-AUC), як об'єднання моделей, навчених на різних рівнях зменшення розмірності, впливає на загальну продуктивність.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
